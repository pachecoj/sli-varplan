Consider a model of latent variables $x$ and observations $\Ycal_{t}
= \{y_1,\ldots,y_{t}\}$.  At each time $t$ a discrete
\emph{action} $a_{t} \in \{1,\ldots,A\}$ parameterizes the
likelihood, denoted \mbox{$p_{a_{t}}(y_{t} \mid x)$}.  Let
$\Dcal_{t} = \{\Ycal_{t},\Acal_{t}\}$ be the set of past observations
and chosen actions \mbox{$\actionset_{t} =
\{a_1,\ldots,a_{t}\}$} at time $t$.  The posterior is then,
\begin{equation}\label{eq:conditional_indep_joint}
  p(x\mid \Dcal_{t}) \propto
    p(x) \prod_{i=1}^{t} p_{a_i}(y_i \mid x)
\end{equation}
The goal of sequential information planning is to choose the sequence
of actions $\Acal$ that minimize entropy of the
posterior~\eqref{eq:conditional_indep_joint}.  Specifically, at time
$t$, action $a_t$ is selected to maximize the posterior MI,
\begin{align}\label{eq:post_mi}
  a_t^{*} &= \argmax_a I(X;Y_t \mid \Dcal_{t-1}) \notag \\
          &= \argmax_a H(X\mid \Dcal_{t-1}) - H_a(X \mid Y_t, \Dcal_{t-1})
          %% &= \argmax_a H(X\mid \Dcal_{t-1}) + H_a(Y_t\mid \Dcal_{t-1})
          %% - H_a(X, Y_t \mid \Dcal_{t-1}).
\end{align}
New observations are then drawn from the appropriate likelihood
$y_t \sim p_{a_t}(\cdot \mid x)$ and the posterior is updated.
However, calculating posterior MI in \EQN\eqref{eq:post_mi} is
complicated for two reasons.  First, entropies involve expectations
under the posterior~\eqref{eq:conditional_indep_joint}.  Second, the
conditional entropy $H(X\mid Y, \Dcal)$ requires evaluation of the
posterior predictive distribution $p(y\mid \Dcal)$ as in,
\[
  H(X\mid Y, \Dcal) = \EE\left[
    - \log \frac{p(x,y\mid \Dcal)}{ p(y\mid \Dcal) } \right],
\]
where we have dropped explicit indexing on time.  One approach is to
estimate this over samples \mbox{$\{y^i_t\} \sim
p_a(y\mid \Dcal_{t-1})$}.  The resulting empirical plug-in estimator
of MI is,
%% \begin{equation}\label{eq:emp_mi}
%%   \hat{I}_a = \frac{1}{N} \sum_{i=1}^N \log \frac{ p_a(y_t^i \mid x^i)
%%   }{ \frac{1}{M} \sum_{j=1}^M p_a(y_t^i \mid x^{ij}) }.
%% \end{equation}
\begin{equation}\label{eq:est_margent}
  \hat{I}_a = - \frac{1}{N} \sum_{i=1}^N \log \frac{
    p_a(y_t^i\mid x^i) }{\frac{1}{M}
        \sum_{j=1}^M p_a(y_t^i \mid x^{ij})}.
\end{equation}
Independent samples $\{x^{ij}\}_{j=1}^M \sim p(x \mid \Dcal_{t-1})$
are required for each action, and observation sample, to ensure
estimates are independent, thus increasing sample complexity.  While
the estimator~\eqref{eq:est_margent} is consistent, it is biased.
Moreover, bias is known to decay slowly~\citep{zheng2018robust,
rainforth2018nesting}.

%% %% \mbox{$I(X;Y_t \mid \Ycal_{t-1}, \Acal_{t-1})$}. 
%% %% \begin{align}
%% %%   a_t^{*} &= \argmax_a I_a(X;Y_t \mid \Ycal_{t-1}, \Acal_{t-1}) \\
%% %%     &= H(X\mid \Ycal_{t-1}, \Acal_{t-1}) - H_a(X, Y_t \mid
%% %%       \Ycal_{t-1}, \Acal_{t-1}). \notag
%% %% \end{align}
%% \begin{equation}
%%   a_t^{*} = \argmax_a H(X) + H_a(Y_t) - H_a(X, Y_t). \notag
%% \end{equation}


