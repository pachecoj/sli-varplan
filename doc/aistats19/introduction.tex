In recent years, Bayesian machine learning research has given much
attention to posterior inference algorithms for models where posterior
calculation is computationally prohibitive.  Such methods are
typically validated using predictive accuracy, or log-likelihood, of
static test data.  By contrast, comparatively little attention has
been given to the setting where the observed data are conditioned on
decisions made based on the result of inference.  Sequential decision
making, which repeatedly applies this inference-decision-observation
cycle, requires high quality decisions over a sustained period.

%% The resulting \emph{planning} problem must make
%% decisions based on the posterior distribution, which reflects
%% knowledge and uncertainty about the state of nature.

Sequential decision making in the context that we have presented has
long been considered in the statistics literature as Bayesian
experimental design~\citep{blackwell50, lindley56, bernardo79a}.  A
natural utility for selecting experiments is mutual information (MI),
which measures the expected reduction in posterior uncertainty.
Experiments are conducted for information gathering, and so the MI
utility is purely exploratory.  This is in contrast to
the planning problems arising in the reinforcement learning and
robotics literature, which balance exploration of information
gathering with exploitation of an alternate
reward~\citep{sutton1998reinforcement}.

Statistical experiment design typically presumes that the cost of
experiments, or the cost of observation, far exceed the cost of
computation, and therefore rely on Markov chain Monte Carlo (MCMC)
methods for computation.  Such an approach is impractical for
high-throughput decision systems.  Moreover, Monte Carlo estimates of
MI have been shown to be biased due to the use of nested Monte Carlo
estimation, and that the rate of bias decay can be
slow~\citep{zheng2018robust, rainforth2018nesting}.

We present a comprehensive approach to inference and planning, which
we refer to as variational information planning (VIP).  At the core of
our approach is a series of variational approximations to the
posterior and mutual information~\citep{wainwright_jordan}.  A core
challenge is that, while variational approximations tend to yield
predictive accuracy, their estimates of posterior uncertainty can be
arbitrarily poor~\citep{giordano2015linear, turner2011two}.  Since MI
is a measure of posterior uncertainty, naive applications of
variational approximations for information planning will tend to yield
poor decisions.

To address poor uncertainty approximation we decouple the variational
posterior from planning and maximize a well-known lower bound of MI
resulting from Gibbs' inequality~\citep{agakov2004algorithm}.  The
bound is maximized over an auxiliary model, which is strictly more
expressive than the exponential family posterior approximation, thus
allowing for better representations of uncertainty.  Moreover, we show
that when this class of models is conditionally in the exponential
family, the resulting optimization problem is convex.  We also show
connections to MI approximation based on moment matching operations,
and that it is equivalent to our approach in some restricted settings.
Finally, we demonstrate effectiveness on a variety of problems
including nonlinear target tracking in a sensor network, gene
regulatory network inference, and active learning in the labeled LDA
model (LLDA).


