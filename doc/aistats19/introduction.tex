Bayesian machine learning research has paid much attention to the
development of posterior inference algorithms, yet comparatively
little attention to methods for decision making based on the results
of inference.  In this paper we explore sequential decision making
based on information theoretic quantities.  Specifically, we introduce
efficient methods for \emph{information planning}, where decisions are
generated by maximizing the mutual information (MI)
utility~\citep{WilliamsThesis}.

Our setting resembles Bayesian experiment design~\citep{lindley56},
where experiments are chosen to minimize uncertainty over a quantity
of interest.  MI has long been used as a design utility in this
setting~\citep{blackwell50, bernardo79a}.  Unlike experiment design,
which typically assumes the cost of a measurement dominates that of
inference, our focus is on high throughput sequential decision
systems.  Where the former relies on Markov chain Monte Carlo (MCMC),
we present a comprehensive approach to inference and planning based on
efficient variational approximations.

Our approach, which we call variational information planning (VIP),
maintains a series of variational approximations to the posterior and
MI utility.  For the planning stage, VIP extends a lower bound of
MI~\citep{agakov2004algorithm} to the sequential setting.  The bound
is optimized over an auxiliary distribution approximating the expected
posterior.  We demonstrate that VIP yields a convex optimization for
exponential family auxiliary models, leading to efficient planning.
We establish optimality conditions for the natural parameters of this
family, and show that they are a relaxation of the well known moment
matching conditions.

%% Our setting differs from both Bayesian experimental design and RL in a
%% number of ways.  Traditional experiment design typically assumes the
%% cost of observation outweighs that of inference, and thus relies on
%% Markov chain Monte Carlo (MCMC) methods for inference.  MI is then
%% estimated over samples, resulting in estimator bias with slow
%% convergence~\citep{zheng2018robust, rainforth2018nesting}.  In
%% comparison to RL planning, our utility of interest is thus purely
%% exploratory, thus contrasting with the exploration-exploitation
%% trade-off common in RL planning~\citep{sutton1998reinforcement}.
%% Other differences with RL include the use of a structured statistical
%% model and representation of latent variables.

%% Statistical experiment design typically presumes that the cost of
%% experiments, or the cost of observation, far exceed the cost of
%% computation, and therefore rely on Markov chain Monte Carlo (MCMC)
%% methods for computation.  Such an approach is impractical for
%% high-throughput decision systems.  Moreover, Monte Carlo estimates of
%% MI have been shown to be biased due to the use of nested Monte Carlo
%% estimation, and that the rate of bias decay can be
%% slow~\citep{zheng2018robust, rainforth2018nesting}.

Despite good predictive accuracy, variational approximations of
posterior uncertainty can be poor~\citep{giordano2015linear,
turner2011two}.  Thus, a naive variational approach will tend to yield
poor planning decisions.  We address these issues by defining a class
of auxiliary distributions that, when conditioned on future
observations, define exponential families.  This set allows arbitrary
nonlinear dependence on the observation variable, and is thus strictly
larger than the set of jointly exponential family models.

In our experiments we demonstrate that VIP is sufficiently flexible to
apply in a variety of problem instances such as nonlinear target
tracking in a sensor network, experiment design, and active learning.
Moreover, VIP meets or exceeds the accuracy of methods based on exact
inference, MCMC requiring more computation, or specialized variational
approximations. 

%% and maximize a
%% well-known lower bound of MI resulting from Gibbs'
%% inequality~\citep{agakov2004algorithm}.  The bound is maximized over
%% an auxiliary model, which is strictly more expressive than the
%% exponential family posterior approximation, thus allowing for better
%% representations of uncertainty.  Moreover, we show that when this
%% class of models is conditionally in the exponential family, the
%% resulting optimization problem is convex.  We also show connections to
%% MI approximation based on moment matching operations, and that it is
%% equivalent to our approach in some restricted settings.  Finally, we
%% demonstrate effectiveness on a variety of problems including nonlinear
%% target tracking in a sensor network, gene regulatory network
%% inference, and active learning in the labeled LDA model (LLDA).


