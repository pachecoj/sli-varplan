We demonstrate VIP in a variety of contexts including sensor
selection, Bayesian experiment design, and active learning.  The
primary comparison in most settings is to MCMC inference or exact
numerical inference when possible, along with empirical mean
estimation of the MI for planning.  In this way, our motivation is to
demonstrate comparable accuracy using more efficient variational
methods.  For the more complex case of LLDA we in fact observe
sustained improvements over baseline.

\subsection{Sensor Selection}

We begin with estimating target position in a network of sensors, each
with fixed position.  Due to communication constraints we can draw
measurements from only a single sensor at each time.  At each planning
stage we must draw measurements from the most informative sensor.

We consider estimation in, both, static and dynamic settings.  In both
cases we optimize the MI lower bound over a linear Gaussian auxiliary
distribution $\omega(x \mid y_t) = \Ncal(a y_t, \sigma^2)$, which can be
solved in closed-form.  We compare the impact of inference on
predictive accuracy by comparing exact numerical calculation,
variational inference, and MCMC.


%% We model sensor
%% noise as depending on the relative distance to the unknown target;
%% sensors further from the target produce less accurate detections.  

\textbf{Static Estimation.}  A stationary target has position drawn
from a Gaussian prior $x \sim \Ncal(m,\sigma^2)$.  Observations are
drawn from one of $K$ sensors, each with fixed position $l_k$.  Sensor
noise is modeled as a two-component Gaussian mixture model,
\[
  y \mid x; k \sim w * \Ncal(0, v_0) + (1-w) * \Ncal(x, v_k(x)).
\]
The mixture consists of a noise distribution with fixed variance $v_0$
and an observation model with noise variance increasing with relative
distance: \mbox{$v_k(x) = |l_k - x| + v_1$}.

\begin{figure}
  \centering
  \begin{tabular}{cc}
    \hspace{-3mm}\includegraphics[width=0.24\textwidth]{ss_stateerr_maxIters100_Nsamp50_Nruns20.pdf} &
    \hspace{-5mm}\includegraphics[width=0.24\textwidth]{ss_MI_maxIters100_Nsamp50_Nruns20.pdf}
  \end{tabular}
  
  \caption{\small\textbf{Static target estimation.} Estimation of a 1D
    target position in a network of $K=10$ equally spaced sensors.
    Mean (solid) plus STDEV (dashed) over 20 realizations.  \emph{Left:}
    Variational planning based on EP inference yields comparable error
    in state estimate compared to exact inference with empirical MI
    estimates. ADF inference yields higher error.  \emph{Right:}
    Empirical estimates based on the numerical posterior most
    accurately estimate MI.  VIP bound gap is consistently lower for
    more accurate EP posterior estimates as compared to
    ADF.}
  \label{fig:static}
\end{figure}

\begin{figure*}[!t]
  \centering
  \hspace{-3mm}
  \includegraphics[width=1.0\textwidth]{tracking_single}

  \caption{\small\textbf{Nonlinear tracking example} in a field of
    $K=10$ equally spaced, stationary, sensors.  The best comparison
    is to numerical approximation to MI and the posterior distribution
    (\emph{top-center}).  For reference, we have also included an
    \emph{oracle} which selects the sensor closest to the true target
    location (\emph{left column}).  In typical cases such as this one,
    we see that VIP state error is comparable to empirical estimation
    under the same posterior approximation.  However, VIP shows lower
    accuracy when planning is computed against an approximate
    posterior, in this case particle filtering (PF).}

  \label{fig:tracking_single}
\end{figure*}

\textbf{Dynamical System.} We extend the setting to a nonlinear
dynamical system frequently used in the sequential Monte Carlo
literature~\citep{kitagawa1996monte, gordon1993novel,
  cappe2007overview},
\[
  \Ncal\left(0.5 x_{t-1} + 25 x_{t-1} / (1+x_{t-1}^2)
  + 8 \cos(1.2t), \sigma_u^2\right).
\]
To keep consistent with prior work we model observations
as, \mbox{$y_t \mid x_t; k \sim \Ncal(x_t^2/20, v_{tk}(x_t))$}.  The
variance function $v_{tk}(x_t)$ is identical to our static example.
To demonstrate flexibility additionally replace variational inference
with a particle filter.  \FIG\ref{fig:tracking_single} demonstrates an
example scenario.

%\subsubsection{Results}

\textbf{State predictions competitive with empirical.}  In both cases
VIP produces state estimates with similar or better accuracy to
empirical planning, depending on the chosen posterior approximation.
In the static estimation model we find similar accuracy between exact
numerical inference with empirical planning and EP inference with VIP
planning (\FIG\ref{fig:static}; left).  In the tracking model we also
consider exact inference with VIP planning, for which median error is
lowest.  When comparing particle filter inference VIP and empirical
planning accuracy are comparable, with the former showing slightly
lower median error (\FIG\ref{fig:dynamic}; left).

\textbf{Planning is sensitive to posterior accuracy.}  We also find
that estimates of the state estimate, and of the MI calculation, are
sensitive to accuracy of the posterior approximation.  In the static
case we compare against assumed density filtering (ADF), which is more
numerically stable than EP but tends to produce less accurate
posterior approximations.  Planning based on the ADF posterior
produces less accurate state estimates (\FIG\ref{fig:static}; left)
and higher error MI estimates (\FIG\ref{fig:static}; right).
Similarly, use of particle filter inference in the tracking model
increases error for both the state (\FIG\ref{fig:dynamic}; left) and
MI calculation (\FIG\ref{fig:dynamic}; right).



\begin{figure}[t]
  \centering
  \begin{tabular}{cc}
    \hspace{-3mm}\includegraphics[width=0.24\textwidth]{tracking_state_err} &
    \hspace{-3mm}\includegraphics[width=0.24\textwidth]{tracking_sensor_err}
  \end{tabular}
  
  \caption{\small\textbf{Nonlinear tracking for 20 random
  trials.}  \emph{Left:} Exact inference with variational planning
  yields the lowest RMS state error.  Particle filter inference with
  500 particles and variational planning (PFVI) yields lower median
  error compared to MC estimates of information (MCMI), though wider
  error quantiles.  \emph{Right:} Again, Exact VI shows the lowest RMS
  error of the selected sensor position w.r.t.~optimal, whereas PFVI
  and MCMI both have higher error, again with PFVI having larger
  quantiles.}
  \vspace{-4mm}
  \label{fig:dynamic}

\end{figure}





\subsection{Gene Regulatory Network}

\cite{steinke2007experimental}, and later~\cite{seeger2008bayesian},
introduced a heuristic approach to sequential experiment design which
shares components of our current method.  Their approach relies on EP
inference and related approximations of the MI utility.  Using an
example from these papers, we compare VIP for the discovery of causal
gene interactions.

Let $x\in\RR^n$ represent the deviation of $n$ gene expression levels
from steady state.  The matrix $A\in\RR^{n\times n}$ represents causal
interactions, with sparse entries drawn i.i.d.~from a Laplace
distribution,
\begin{equation}\label{eq:sparselin}
  \!\!\!p(A,x) \propto \prod_{i=1}^n \Ncal(u_i \mid a_i^T
    x, \sigma^2) \prod_{j=1}^n \textrm{Laplace}(a_{ij} \mid \lambda) 
\end{equation}
where $a_i$ is the $i^{\text{th}}$ row of matrix $A$.  Here $u$
represents an external control vector (perturbation).  Interventions
include up regulating $u_i>0$, down regulation $u_i<0$ and no
intervention $u_i=0$ for the $i^{\text{th}}$ gene.  Observe that the
joint~\eqref{eq:sparselin} is unnormalized since the likelihood term
is not a normalized distribution of $x$.

\begin{figure}[t]
  \centering
  \begin{tabular}{cc}
    \hspace{-3mm}\includegraphics[width=0.24\textwidth]{sparselin_iAUC_N100_norandom_run20_norepeats} &
    \hspace{-3mm}\includegraphics[width=0.22\textwidth]{sparselin_noise_N100_norandom_run20_norepeats}
  \end{tabular}
  \caption{\small\textbf{Sparse linear model.} Average +/- STDEV
    computed for $n=50$ nodes over 20 random networks.  \emph{Left:}
    AUC for edges with true weights $|a_{ij}|>0.1$ plotted for each
    intervention experiment.  VIP shows similar results to Steinke and
    Seeger with slight improvement for less than 25 experiments.
    \emph{Right:} Average AUC at varying noise levels are broadly
    similar to Steinke and Seeger. The dip at moderate SNR levels may
    be due to our choice of a simple approximating family (linear
    Gaussian).}
  
  \label{fig:sparselin}
\end{figure}

We compare to the variational method of~\cite{steinke2007experimental}
and later~\cite{seeger2008bayesian} which maintain a mean field
Gaussian posterior approximation using EP:
\[
q(A) = \prod_i p_i^{(0)}(a_i) \prod_j \widetilde{t}_{ij}(a_{ij}).
\]
Here, $p^{(0)}_i(a_i)$ approximates the base measure \mbox{$N(u_i \mid
  a_i^T x, \sigma^2)$} and \mbox{$\widetilde{t}_{ij}(a_{ij})$} the
Laplace factors.  Given past observations $\Dcal$ and a new control
and observation pair $\{x_*,u_*\}$, maximizing MI is (approximately)
equivalent to maximizing \mbox{$\EE_{x_*}\!\left[\, \KL{q'}{q}
    \,\right]$},
%% \begin{equation}\label{eq:max_kl}
%%   \max_{u_*} \; \EE_{x_*}\!\left[\, \KL{q'}{q} \,\right],
%% \end{equation}
where approximation comes from the update posterior \mbox{$q'(A)
  \approx p(A \mid \Dcal \cup \{x_*,u_*\})$}.  The previous authors
approximate expectation over samples $\{x_{*}^{k}\}$ from the
predictive distribution $p(x_{*} \mid \Dcal, u_{*})$.  Since this
approach requires updating the EP posterior $q'(A)$ for each sample
$x_{*}^k$, which is prohibitive, they instead propose a
non-iterative approximation which only updates the Gaussian base measure
$p^{(0)}(A)$ at each sample.

\textbf{Similar results to specialized method.} We optimize the MI
bound over a linear Gaussian approximation for 20 random trials and
report area under the curve (AUC) for edge prediction
(\FIG\ref{fig:sparselin}; left).  Steinke and Seeger approximate MI by
updating only the base measure $p^{(0)}$, which involves a moment
matching projection $\EE_{q'}[ \phi(A) ] = \EE_{\hat{p}}[ \phi(A) ]$,
where $\hat{p}(A)$ is the augmented distribution, which is similar to
the moment matching solution discussed in \SEC\ref{sec:moment_match}.
As a result, VIP reduces to a solution similar to that of Steinke and
Seeger, and results are comparable for more than 30 interventions.
Results remain similar across varying noise levels
(\FIG\ref{fig:sparselin}; right), albeit with a slight drop in
accuracy at moderate SNR.  We hypothesize that this intermediate
region depends more strongly on good MI approximations, and that VIP
would benefit from a more flexible approximating distribution than the
linear Gaussian one chosen.


\textbf{Improved AUC for fewer interventions.}  Despite similarity in
the methods, we do observe small improvements at early interventions.
In particular, Steinke and Seeger observe that their proposed
experimental design approach performs poorly for few interventions and
propose a hybrid method which randomly selects the first 20
interventions, then performs information guided selection thereafter.
Random selection still performs well in this regime.

%% which matches
%% moments of $q^{'}$ to those of.  Specifically, the
%% augmented distribution is given by,
%% \[
%%   \hat{p}(a_i, x_*) \propto \Ncal(u_* \mid a_i^T
%%   x_*, \sigma^2) \prod_j \widetilde{t}_{ij}(a_{ij}).
%% \]
%% The EP update then matches moments to the augmented distribution above
%% for each row $a_i$.
%% %% $\EE_{\hat{p}}[a_i] = \EE_{q'}[ a_i ]$ and $\text{var}_{\hat{p}}[ a_i
%% %% ] = \text{var}_{q'}[ a_i ]$ for each row $a_i$.
%% %% \[
%% %%   q' \Leftrightarrow \argmin_{q'} \KL{}{q'}
%% %% \]

\subsection{Active Learning for Labeled LDA}\label{sec:llda}

\begin{figure}[t]
  \centering
  \includegraphics[width=0.45\textwidth]{llda/llda_model.pdf}
  
  \caption{\small\textbf{Labeled LDA} graphical model augments
    standard LDA with semi-supervised annotations $y_{dn}$ shown as
    shaded dashed nodes.  Each stage of active learning selects
    unlabeled item $(d,n)$ maximizing mutual information
    $I(\Psi,Y_{dn})$ between topics $\Psi$ and annotations $Y$, as in
    \EQN\eqref{eq:maxmi_llda}.  }
  \label{fig:llda_model}
\end{figure}


\begin{figure*}
  \begin{tabular}{ccc}
    \hspace{-3mm}\includegraphics[width=0.32\textwidth]{llda/topics_random_runid_5} &
    \includegraphics[width=0.32\textwidth]{llda/topics_gibbs_runid_5} &
    \includegraphics[width=0.32\textwidth]{llda/topics_vip_runid_5} \\
    {\small\textbf{Gibbs + Random}} & {\small\textbf{Gibbs +
        Empirical}} & {\small\textbf{EP + VIP}}
  \end{tabular}

  \caption{\small \textbf{Learned LLDA topics} from a corpus of $D=50$
    documents, each with $N_d=25$ words drawn from the bars topics
    with a $W=25$ word vocabulary.  We model Topic 0 as a \emph{rare}
    topic (see text).  Gibbs estimates are averaged over $1000$
    samples drawn from parallel chains.  Topic estimates under EP
    inference with selection using VIP (\emph{right}) are broadly
    similar to Gibbs when using empirical MI estimates for selection
    (\emph{center}), though at reduced computational cost.  Gibbs
    estimates have higher noise in low probability regions.
    Annotation based on random selection (\emph{left}) performs poorly
    regardless of the inference method -- Gibbs shown.}

  \label{fig:llda_topics}
\end{figure*}

\begin{figure}[t]
  \centering
  \hspace{-4mm}\includegraphics[width=0.53\textwidth]{llda/llda_tverr} 
  
  \caption{\small\textbf{Total variation (TV) error} for all topics on
    the ``bars'' dataset across 10 random trials.  Variational
    planning with fully parameterized softmax shows consistent
    improvement over Gibbs on average (solid).  Gibbs estimates show
    tighter standard deviation (shaded) for planning based on MI
    estimates.  Both inference methods perform similarly for random
    selection.}
  
  \label{fig:llda_tv}
\end{figure}

%% \begin{figure}[t]
%%   \centering
%%   \includegraphics[width=0.45\textwidth]{llda/bound_comparison}
  
%%   \caption{\small\textbf{LLDA Bound Comparison.} Variational MI
%%   estimates for annotations using three approximating families, ranked
%%   in order of increasing value by empirical estimate of MI.  An ideal
%%   approximation would show monotonically increasing values with little
%%   gap.  The conditional Dirichlet model is a poor approximation.  Two
%%   variations on the softmax distribution provide tighter bounds, with
%%   the fully parameterized softmax being slightly
%%   preferred.}  \label{fig:llda_bound}
%% \end{figure}

Labeled LDA (LLDA) is a semi-supervised extension of
LDA~\citep{blei2003latent}.  For $K$ topics, $D$ documents
$d=1,\ldots,D$, and $N_d$ words per document, the standard
unsupervised LDA model is given by,
\begin{align*}
  \theta_d &\sim \text{Dirichlet}(\alpha) && \text{Topic proportions}\\
  \psi_k &\sim \text{Dirichlet}(\beta_k) && \text{Topics}\\
  z_{dn} \mid \theta_d &\sim \text{Cat}(\theta_d) && \text{Topic Labels}\\
  w_{dn} \mid z_{dn}, \psi &\sim \text{Cat}(\psi_{z_{dn}}) && \text{Words}
\end{align*}
As shown in \FIG\ref{fig:llda_model}, LLDA introduces semi-supervised
annotations for each word~\citep{flaherty2005latent}.  We model
annotations as noisy observations of the true topic assignment,
\[
  y_{dn} \mid z_{dn} \sim \text{Cat}(\pi_{z_{dn}}).
\]
This choice ensures interpretable topics as the posterior concentrates
on a preferred ordering of labels.  Other supervised LDA variations
exist~\citep{ramage2009labeled} but we do not consider them here.

Our evaluation uses the ``bars'' dataset~\citep{griffiths2004finding}
where topics can be visualized as a set of vertical and horizontal
\emph{bars} (see \FIG\ref{fig:llda_topics}).  To amplify the effect of
informative annotations we model a \emph{rare} topic with a
non-symmetric Dirichlet prior over topic proportions: $\alpha = (0.05, 1, 1,
\ldots, 1)^T$.


\textbf{Active Learning} At each learning stage $t$ the planner
selects an annotation $y_{d^*n^*}$ maximizing posterior MI:
\begin{equation}
  (d^*,n^*) = \argmax_{(d,n)} I(\Psi, Y_{dn} \mid \Wcal, \Ycal_{t-1}),
  \label{eq:maxmi_llda}
\end{equation}
with observed annotations $\Ycal_{t-1}$ and $\Wcal$ the corpus of
words.  \EQN\eqref{eq:maxmi_llda} is an instance of the annotation
model (\SEC\ref{sec:annotation}) as integration over nuisance
variables induces dependence among annotations.  We choose a softmax
auxiliary distribution:
\[
  \omega(y = k \mid \psi) \propto \exp( w_k^T \text{vec}(\psi_k) + w_{0k} ),
\]
which has a number of beneficial properties: first, it ensures
convexity of the planning objective~\eqref{eq:maxmi_llda} in the
parameters $w$ (\SEC\ref{sec:optim}).  Second, the marginal
distribution $p(y)$ is in the exponential family (discrete) thus
ensuring simple evaluation of the MI bound (\SEC\ref{sec:eval}).

\textbf{Lower topic error compared to MCMC.}  We compare VIP using EP
inference~\citep{broderick2013streaming} to empirical MI planning
based on Gibbs samples.  Observe that MI estimates require averaging
over topic samples, and thus must account for topic label switching.
We found that any reasonable alignment (e.g. MAP) resulted in poor
estimates~\citep{stephens2000dealing}.  We instead relabel Gibbs
samples to minimize absolute error w.r.t.~the \emph{true topics},
which would not be feasible in practice.  \FIG\ref{fig:llda_tv}
reports total variation (TV) error across topics $\sum_k \|\psi_k -
\hat{\psi}_k\|_1$, based on the posterior mean estimate $\hat{\psi}$.
We found that increasing from the reported 1000 Gibbs samples did not
lead to significant improvements.  We instead suspect that poor MCMC
results are due to a combination of MI estimator bias and local
optima.



%% MI as $I(\Psi,Y_{dn}) \geq H(Y_{dn})
%% + \EE[ \log \omega(Y_{dn} \mid \Psi) ]$ using the following softmax
%% distribution,
%% \begin{equation}
%%   \omega(Y = k \mid \Psi) \propto \exp( w_k^T \text{vec}(\Psi) +
%%   w_{0k} ).
%% \end{equation}

%% which is in the exponential family with natural parameters
%% $\theta(\Psi) = (w_1^T \text{vec}(\Psi) + w_{01}, \ldots,
%% w_K^T \text{vec} + w_{0K})^T$.





